{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 5.1] 모델 빌딩 파이프라인 개발 (SageMaker Model Building Pipeline 모든 스텝)\n",
    "\n",
    "이 노트북은 아래와 같은 목차로 진행 됩니다. 전체를 모두 실행시에 완료 시간은 **약 30분** 소요 됩니다.\n",
    "\n",
    "- 0. SageMaker Model Building Pipeline 개요\n",
    "- 1. 파이프라인 변수 및 환경 설정\n",
    "- 2. 파이프라인 스텝 단계 정의\n",
    "\n",
    "    - (1) 전처리 스텝 스텝 정의    \n",
    "    - (2) 모델 학습을 위한 학습 스텝 정의 \n",
    "    - (3) 모델 평가 스텝\n",
    "    - (4) 모델 등록 스텝\n",
    "    - (5) HPO 단계    \n",
    "    - (6) 최고 모델 등록 스텝    \n",
    "    - (6) HPO 스텝\n",
    "    - (7) 조건 스텝\n",
    "    \n",
    "- 3. 모델 빌딩 파이프라인 정의 및 실행\n",
    "- 4. Pipleline 캐싱 및 파라미터 이용한 실행\n",
    "- 5. 정리 작업\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.SageMaker Model Building Pipeline 개요\n",
    "\n",
    "Amazon SageMaker 모델 구축 파이프라인은 직접 SageMaker 통합을 활용하는 머신 러닝 파이프라인을 구축하기 위한 도구입니다. 이러한 통합으로 인해 많은 단계 생성 및 관리를 처리하는 도구를 사용하여 파이프라인을 생성하고 오케스트레이션용 SageMaker Projects를 설정할 수 있습니다. SageMaker 파이프라인은 다른 파이프라인에 비해 다음과 같은 이점을 제공합니다\n",
    "\n",
    "- 상세 사항은 개발자 가이드 참조 하세요. --> [Amazon SageMaker 모델 구축 파이프라인](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 파이프라인 변수 및 환경 설정\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "\n",
    "%store -r "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 모델 빌딩 파이프라인 변수 생성\n",
    "\n",
    "파이프라인에 인자로 넘길 변수는 아래 크게 3가지 종류가 있습니다.\n",
    "- 프로세싱 스텝을 위한 인스턴스 타입 및 인스턴스 수\n",
    "    - 데이터 전처리 스텝 및 실시간 앤드 포인트 스텝에 사용 됨.\n",
    "- 훈련 스텝을 위한 인스턴스 타입 및 인스턴스 수    \n",
    "- 모델 평가를 통해 나온 validation:roc-auc 에 대한 분기 조건 값\n",
    "- 원본 데이터 세트에 대한 S3 주소\n",
    "    - 데이터 전처리 스텝에서 사용 됩니다.\n",
    "- 모델 레지스트리에 모델 등록시에 모델 승인 상태 값    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "training_instance_count = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "model_eval_threshold = ParameterFloat(\n",
    "    name=\"model2eval2threshold\",\n",
    "    default_value=0.85\n",
    ")\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐싱 정의\n",
    "\n",
    "- 참고: 캐싱 파이프라인 단계:  [Caching Pipeline Steps](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines-caching.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, \n",
    "                           expire_after=\"7d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 파이프라인 스텝 단계 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 전처리 스텝 단계 정의\n",
    "- input_data_uri 입력 데이타를 대상으로 전처리를 수행 합니다.\n",
    "\n",
    "크게 아래와 같은 순서로 정의 합니다.\n",
    "- 프로세싱 오브젝트 정의 (SKLearnProcessor)\n",
    "- 프로세싱 스텝 정의\n",
    "    - 일력 데이터 세트\n",
    "        - source: S3 경로 (input_data_uri)\n",
    "        - destination: 도커 컨테이너의 내부 폴더 위치\n",
    "    - 출력 위치\n",
    "        - 훈련 전처리 데이터 결과 위치\n",
    "        - 테스트 전처리 데이터 결과 위치\n",
    "    - 프로세싱 코드\n",
    "    - 프로세싱 코드에 넘길 인자 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processing_instance_type ='ml.m5.xlarge'\n",
    "split_rate = 0.2\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-fraud-process\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# print(\"input_data: \\n\", input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "    \n",
    "step_process = ProcessingStep(\n",
    "    name=\"FraudProcess\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "#         ProcessingInput(source=input_data_uri,destination='/opt/ml/processing/input'),\n",
    "        ProcessingInput(source=input_data, destination='/opt/ml/processing/input'),        \n",
    "         ],\n",
    "    outputs=[ProcessingOutput(output_name=\"train\",\n",
    "                              source='/opt/ml/processing/output/train'),\n",
    "             ProcessingOutput(output_name=\"test\",\n",
    "                              source='/opt/ml/processing/output/test')],\n",
    "    job_arguments=[\"--split_rate\", f\"{split_rate}\"],        \n",
    "    code= 'src/preprocessing.py',\n",
    "    cache_config = cache_config, # 캐시 정의\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 모델 학습을 위한 학습단계 정의 \n",
    "\n",
    "학습 스텝을 정의하기 위해서는 크게 아래와 같은 과정이 있습니다.\n",
    "- XGBoost Estimator 정의\n",
    "- 학습 스텝 정의\n",
    "    - 아래와 같은 중요한 인자가 필요 합니다.\n",
    "        - Estimator (위에서 정의한 것 사용)\n",
    "        - 훈련을 위한 입력 데이터 위치\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 훈련 변수 및 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'fraud2train'\n",
    "estimator_output_path = f's3://{bucket}/{prefix}/training_jobs'\n",
    "\n",
    "base_hyperparameters = {\n",
    "       \"scale_pos_weight\" : \"29\",        \n",
    "        \"max_depth\": \"6\",\n",
    "        \"alpha\" : \"0\", \n",
    "        \"eta\": \"0.3\",\n",
    "        \"min_child_weight\": \"1\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"num_round\": \"100\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instance_type ='ml.m5.xlarge'\n",
    "\n",
    "xgb_train = XGBoost(\n",
    "    entry_point = \"xgboost_script.py\",\n",
    "    source_dir = \"src\",\n",
    "    output_path = estimator_output_path,\n",
    "    code_location = estimator_output_path,\n",
    "    hyperparameters = base_hyperparameters,\n",
    "    role = role,\n",
    "    instance_count = training_instance_count,\n",
    "    instance_type = training_instance_type,\n",
    "    framework_version = \"1.0-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련의 입력이 이전 전처리의 결과가 제공됩니다.\n",
    "- `step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/workflow/steps.py:391: UserWarning: Profiling is enabled on the provided estimator. The default profiler rule includes a timestamp which will change each time the pipeline is upserted, causing cache misses. If profiling is not needed, set disable_profiler to True on the estimator.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"FraudTrain\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            # s3_data= train_preproc_dir_artifact,            \n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "    },\n",
    "    cache_config = cache_config, # 캐시 정의    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 모델 평가 단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearnProcessor 의 기본 도커 컨테이너 지정\n",
    "ScriptProcessor 의 기본 도커 컨테이너로 Scikit-learn를 기본 이미지를 사용함. \n",
    "- 사용자가 정의한 도커 컨테이너도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_eval = SKLearnProcessor(\n",
    "                             framework_version= \"0.23-1\",\n",
    "                             role=role,\n",
    "                             instance_type=processing_instance_type,\n",
    "                             instance_count=1,\n",
    "                             base_job_name=\"script-fraud-scratch-eval\",\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가 지표를 jons 파일에 저장을 하고 property로 등록을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"FraudEval\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source= step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "        destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"src/evaluation.py\",\n",
    "    cache_config = cache_config, # 캐시 정의    \n",
    "  property_files=[evaluation_report], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 모델 등록 스텝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 그룹 생성\n",
    "- 위의 step_eval 에서 S3 로 올린 evaluation.json 파일안의 지표를 \"모델 레지스트리\" 안에 모델 패키지의 모델 버전 등록시에 삽입함\n",
    "\n",
    "- 참고\n",
    "    - 모델 그룹 릭스팅 API:  [ListModelPackageGroups](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ListModelPackageGroups.html)\n",
    "    - 모델 지표 등록: [Model Quality Metrics](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-monitor-model-quality-metrics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model group exists\n",
      "Create model group\n",
      "ModelPackageGroup Arn : arn:aws:sagemaker:us-east-1:057716757052:model-package-group/sagemaker-pipeline-step-by-step-phase02\n"
     ]
    }
   ],
   "source": [
    "model_package_group_name = f\"{project_prefix}\"\n",
    "model_package_group_input_dict = {\n",
    " \"ModelPackageGroupName\" : model_package_group_name,\n",
    " \"ModelPackageGroupDescription\" : \"Sample model package group\"\n",
    "}\n",
    "response = sm_client.list_model_package_groups(NameContains=model_package_group_name)\n",
    "if len(response['ModelPackageGroupSummaryList']) == 0:\n",
    "    print(\"No model group exists\")\n",
    "    print(\"Create model group\")    \n",
    "    \n",
    "    create_model_pacakge_group_response = sm_client.create_model_package_group(**model_package_group_input_dict)\n",
    "    print('ModelPackageGroup Arn : {}'.format(create_model_pacakge_group_response['ModelPackageGroupArn']))    \n",
    "else:\n",
    "    print(f\"{model_package_group_name} exitss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "\n",
    "# 위의 step_eval 에서 S3 로 올린 evaluation.json 파일안의 지표를 \"모델 레지스트리\" 에 모데 버전 등록시에 삽입함\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name= \"FraudcRegisterhModel\",\n",
    "    estimator=xgb_train,\n",
    "    image_uri= step_train.properties.AlgorithmSpecification.TrainingImage,\n",
    "    model_data= step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) HPO 스텝\n",
    "- 하이퍼 파라미터 튜닝 스텝을 정의 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "}\n",
    "\n",
    "\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb_train, objective_metric_name, hyperparameter_ranges, \n",
    "    max_jobs=5,\n",
    "    max_parallel_jobs=5,\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "    \n",
    "step_tuning = TuningStep(\n",
    "    name = \"FraudTuning\",\n",
    "    tuner = tuner,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            # s3_data= train_preproc_dir_artifact,            \n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "    },    \n",
    "    cache_config = cache_config, # 캐시 정의        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) 최고 모델 등록 스텝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최고의 모델 생성 및 등록\n",
    "\n",
    "하이퍼파라미터 튜닝 작업을 성공적으로 완료한 후TuningStep의 교육 작업에 의해 생성된 모델 아티팩트에서 SageMaker 모델을 생성하거나 모델 레지스트리에 모델을 등록할 수 있습니다.\n",
    "\n",
    "\n",
    "TuningStep 클래스의 get_top_model_s3_uri 메서드를 사용하여 최고 성능의 모델 버전의 모델 아티팩트를 가져옵니다.\n",
    "\n",
    "- `model_bucket_key` 는 튜닝 스텝을 통해서 생성된 훈련 잡의 위치 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_bucket_key:  sagemaker-us-east-1-057716757052/fraud2train/training_jobs\n",
      "model_package_group_name:  sagemaker-pipeline-step-by-step-phase02\n"
     ]
    }
   ],
   "source": [
    "model_bucket_key = estimator_output_path.split('//')[1]\n",
    "print(\"model_bucket_key: \", model_bucket_key)\n",
    "print(\"model_package_group_name: \", model_package_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "\n",
    "step_register_best = RegisterModel(\n",
    "    name=\"RegisterBestFraudModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_bucket_key),\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) 조건 스텝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class JsonGet has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.auc.value\",\n",
    "    ),\n",
    "    # right=8.0\n",
    "    right = model_eval_threshold\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"FruadMetricCond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_tuning],        \n",
    "    else_steps=[step_register], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.모델 빌딩 파이프라인 정의 및 실행\n",
    "위에서 정의한 아래의 4개의 스텝으로 파이프라인 정의를 합니다.\n",
    "-     steps=[step_process, step_train, step_create_model, step_deploy],\n",
    "- 아래는 약 20분 정도 소요 됩니다. 이후에 스튜디오에서 아래와 같이 확인이 가능합니다.\n",
    "\n",
    "- ![all-pipeline-phase02-wo-cache.png](img/all-pipeline-phase02-wo-cache.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "project_prefix = 'sagemaker-pipeline-phase2-mbp-step-by-step'\n",
    "\n",
    "pipeline_name = project_prefix\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type, \n",
    "        processing_instance_count,\n",
    "        training_instance_type,        \n",
    "        training_instance_count,                \n",
    "        input_data,\n",
    "        model_eval_threshold,\n",
    "        model_approval_status,        \n",
    "    ],\n",
    "\n",
    "    \n",
    "  steps=[step_process, step_train, step_eval, step_cond, step_register_best],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "# definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인을 SageMaker에 제출하고 실행하기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/sagemaker-pipeline-phase2-mbp-step-by-step',\n",
       " 'ResponseMetadata': {'RequestId': 'b03c7072-69ab-44bf-b871-12b3c2fc3a4a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b03c7072-69ab-44bf-b871-12b3c2fc3a4a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '110',\n",
       "   'date': 'Thu, 23 Jun 2022 11:27:03 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디폴트값을 이용하여 파이프라인을 샐행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 운영: 파이프라인 대기 및 실행상태 확인\n",
    "\n",
    "워크플로우의 실행상황을 살펴봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행이 완료될 때까지 기다립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행된 단계들을 리스트업합니다. 파이프라인의 단계실행 서비스에 의해 시작되거나 완료된 단계를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'RegisterBestFraudModel',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 42, 48, 339000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 42, 49, 607000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/sagemaker-pipeline-step-by-step-phase02/1'}}},\n",
       " {'StepName': 'FraudTuning',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 38, 59, 566000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 42, 47, 391000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TuningJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:hyper-parameter-tuning-job/brnj2j2p3jud-fraudtu-4dfdzcsaa2'}}},\n",
       " {'StepName': 'FruadMetricCond',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 38, 58, 750000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 38, 59, 144000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'Condition': {'Outcome': 'True'}}},\n",
       " {'StepName': 'FraudEval',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 34, 33, 676000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 38, 58, 234000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:processing-job/pipelines-brnj2j2p3jud-fraudeval-05zfvhxh7t'}}},\n",
       " {'StepName': 'FraudTrain',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 31, 30, 860000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 34, 32, 905000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:training-job/pipelines-brnj2j2p3jud-fraudtrain-f1ej9xf9gr'}}},\n",
       " {'StepName': 'FraudProcess',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 27, 4, 949000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 31, 30, 258000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:processing-job/pipelines-brnj2j2p3jud-fraudprocess-14lpxpuftb'}}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pipeline 캐싱 및 파라미터 이용한 실행\n",
    "- 캐싱은 2021년 7월 현재 Training, Processing, Transform 의 Step에 적용이 되어 있습니다.\n",
    "- 상세 사항은 여기를 확인하세요. -->  [캐싱 파이프라인 단계](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines-caching.html)\n",
    "\n",
    "- 아래를 실행하면 아래와 같이 스튜디오에서 확인이 가능합니다.\n",
    "- ![all-pipeline-phase02-cache.png](img/all-pipeline-phase02-cache.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.8 ms, sys: 1.11 ms, total: 19.9 ms\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from IPython.display import display as dp\n",
    "import time\n",
    "\n",
    "if is_cache:\n",
    "    execution = pipeline.start(\n",
    "        parameters=dict(\n",
    "            model2eval2threshold=0.8,\n",
    "        )\n",
    "    )    \n",
    "    \n",
    "    # execution = pipeline.start()\n",
    "    execution.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'FraudcRegisterhModel',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 43, 19, 882000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 43, 20, 531000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/sagemaker-pipeline-step-by-step-phase02/2'}}},\n",
       " {'StepName': 'FruadMetricCond',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 43, 19, 167000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 43, 19, 626000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'Condition': {'Outcome': 'False'}}},\n",
       " {'StepName': 'FraudEval',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 43, 18, 118000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 43, 18, 661000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'CacheHitResult': {'SourcePipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/sagemaker-pipeline-phase2-mbp-step-by-step/execution/brnj2j2p3jud'},\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:processing-job/pipelines-brnj2j2p3jud-fraudeval-05zfvhxh7t'}}},\n",
       " {'StepName': 'FraudTrain',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 43, 16, 864000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 43, 17, 181000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'CacheHitResult': {'SourcePipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/sagemaker-pipeline-phase2-mbp-step-by-step/execution/brnj2j2p3jud'},\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:training-job/pipelines-brnj2j2p3jud-fraudtrain-f1ej9xf9gr'}}},\n",
       " {'StepName': 'FraudProcess',\n",
       "  'StartTime': datetime.datetime(2022, 6, 23, 11, 43, 15, 652000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 6, 23, 11, 43, 15, 955000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'CacheHitResult': {'SourcePipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/sagemaker-pipeline-phase2-mbp-step-by-step/execution/brnj2j2p3jud'},\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:processing-job/pipelines-brnj2j2p3jud-fraudprocess-14lpxpuftb'}}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if is_cache:\n",
    "    dp(execution.list_steps())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 테스트 데이타 추출\n",
    "\n",
    "- 추후에 모델 배포 후 추론을 위해서 전처리된 테스트 데이타를 추출 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_preprocessed_file: \n",
      "  s3://sagemaker-us-east-1-057716757052/FraudProcess-9eb3e47661f2f1f3db35bb21017985f2/output/test\n"
     ]
    }
   ],
   "source": [
    "def get_proc_artifact(execution, client, kind=0):\n",
    "    '''\n",
    "    kind: 0 --> train\n",
    "    kind: 2 --> test\n",
    "    '''\n",
    "    response = execution.list_steps()\n",
    "\n",
    "    proc_arn = response[-1]['Metadata']['ProcessingJob']['Arn'] # index -1은 가장 처음 실행 step\n",
    "    #proc_arn = response[-1]['Metadata']\n",
    "    # print(\"proc_arn: \", proc_arn)\n",
    "    proc_job_name = proc_arn.split('/')[-1]\n",
    "    #print(\"proc_job_name: \", proc_job_name)\n",
    "    \n",
    "    response = client.describe_processing_job(ProcessingJobName = proc_job_name)\n",
    "    test_preprocessed_file = response['ProcessingOutputConfig']['Outputs'][kind]['S3Output']['S3Uri'] # index 1: test 파일    \n",
    "    print(\"test_preprocessed_file: \\n \", test_preprocessed_file)\n",
    "    \n",
    "    return test_preprocessed_file\n",
    "\n",
    "import boto3\n",
    "client = boto3.client(\"sagemaker\")\n",
    "\n",
    "test_preproc_dir_artifact = get_proc_artifact(execution, client, kind=1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'all_mbp_pipeline_name' (str)\n",
      "Stored 'test_preproc_dir_artifact' (str)\n"
     ]
    }
   ],
   "source": [
    "all_mbp_pipeline_name = pipeline_name # 파이프라인 변수 이름을 변경\n",
    "%store all_mbp_pipeline_name\n",
    "%store test_preproc_dir_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
