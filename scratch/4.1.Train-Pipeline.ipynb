{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 4.1] 모델 훈련 스텝 개발 (SageMaker Model Building Pipeline 훈련 스텝)\n",
    "\n",
    "이 노트북은 아래와 같은 목차로 진행 됩니다. 전체를 모두 실행시에 완료 시간은 약 5분-10분 소요 됩니다.\n",
    "\n",
    "- 0. 모델 훈련 개요 \n",
    "- 1. 데이터 세트 로딩 및 기본 훈련 변수 설정\n",
    "- 2. 모델 훈련 코드 확인\n",
    "- 3. 모델 훈련 스텝 개발 및 실행\n",
    "    - 아래의 3단계를 진행하여 SageMaker Model Building Pipeline 에서 훈련 스텝 개발 함. 아래의 (1), (2) 단계는 옵션이지만, 실제 현업 개발시에 필요한 단계이기에 실행을 권장 드립니다.\n",
    "        - (1) [옵션] **[로컬 노트북 인스턴스]**에서 다커 컨테이너로 훈련 코드 실행 (로컬 모드로 불리움)\n",
    "        - (2) [옵션] **[세이지 메이커 호스트 모드]**로 (로컬 노트북 인스턴스에서 실행이 되는 것이 아님) 다커 컨테이너를 통해서 훈련 코드 실행          \n",
    "        - (3) [필수] SageMaker Model Building Pipeline 에서 모델 훈련 스텝 개발 및 실행\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 모델 훈련 개요\n",
    "\n",
    "이 노트북은 세이지 메이커의 Training Job을 통해서 모델 훈련을 합니다. <br>\n",
    "상세한 사항은 개발자 가이드를 참조 하세요. -->  [모델 훈련](https://sagemaker.readthedocs.io/en/stable/overview.html#local-mode)\n",
    "\n",
    "- 일반적으로 크게 4가지의 스텝으로 진행이 됩니다.\n",
    "    - (1) S3에 훈련 파일 준비\n",
    "        - 이전 단계의 전처리시의 결과 파일을 사용 합니다.\n",
    "    - (2) 훈련 알고리즘을 준비 (세이지 메이커 내장 알고리즘 혹은 사용자 정의 알고리즘 사용)\n",
    "        - 이 노트북에서는 사용자 정의 알고리즘을 코드로 기술 했습니다. (훈련 스크립트 모드)\n",
    "    - (3) Training Job을 생성시에 아래와 같은 항목을 제공합니다.\n",
    "        - Training Job을 실행할 EC2(예: ml.m4.2xlarge) 기술\n",
    "        - EC2에서 로딩할 다커 이미지의 이름 기술\n",
    "            - 아래 그림의 ECR(Amazon Elastic Container Registry)에서 다운로드\n",
    "        - S3 입력 파일 경로\n",
    "        - 훈련 코드 경로\n",
    "        - 훈련 결과로서 모델 아티펙트 S3 경로 (지정하지 않으면 디폴트를 사용 합니다.)\n",
    "    - (4) EC2에서 훈련 실행 하여 S3에 모델 아티펙트 저장\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sagemaker-training.png](img/sagemaker-training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.데이터 세트 로딩 및 기본 훈련 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "%store -r \n",
    "# 노트북에 저장되어 있는 변수를 보기 위해서는 주석을 제거하고 실행하시면 됩니다.\n",
    "# %store  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 세트 로딩\n",
    "- 이전 단계(전처리)에서 결과 파일을 로딩 합니다. 실제 훈련에 제공되는 데이터를 확인하기 위함 입니다.\n",
    "- 로딩힐 데이터 파일이 S3에 있는지 변수의 경로를 확인 합니다. (train_preproc_dir_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE train/\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {train_preproc_dir_artifact} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>num_claims_past_year</th>\n",
       "      <th>num_insurers_past_5_years</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>customer_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>collision_type_missing</th>\n",
       "      <th>incident_severity_Major</th>\n",
       "      <th>incident_severity_Minor</th>\n",
       "      <th>incident_severity_Totaled</th>\n",
       "      <th>authorities_contacted_Ambulance</th>\n",
       "      <th>authorities_contacted_Fire</th>\n",
       "      <th>authorities_contacted_None</th>\n",
       "      <th>authorities_contacted_Police</th>\n",
       "      <th>police_report_available_No</th>\n",
       "      <th>police_report_available_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8913.668763</td>\n",
       "      <td>80513.668763</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>99207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19746.724395</td>\n",
       "      <td>26146.724395</td>\n",
       "      <td>41</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>2950</td>\n",
       "      <td>95632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11652.969918</td>\n",
       "      <td>22052.969918</td>\n",
       "      <td>57</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>93203</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11260.930936</td>\n",
       "      <td>115960.930936</td>\n",
       "      <td>39</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>85208</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>27987.704652</td>\n",
       "      <td>31387.704652</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>91792</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0</td>\n",
       "      <td>18052.611626</td>\n",
       "      <td>67152.611626</td>\n",
       "      <td>42</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>93654</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0</td>\n",
       "      <td>34949.202468</td>\n",
       "      <td>51749.202468</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>94305</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0</td>\n",
       "      <td>4063.701410</td>\n",
       "      <td>9963.701410</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>750</td>\n",
       "      <td>2550</td>\n",
       "      <td>95476</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0</td>\n",
       "      <td>17390.520451</td>\n",
       "      <td>20490.520451</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>90680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0</td>\n",
       "      <td>2501.811593</td>\n",
       "      <td>8401.811593</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>2650</td>\n",
       "      <td>98029</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fraud  vehicle_claim  total_claim_amount  customer_age  \\\n",
       "0         0    8913.668763        80513.668763            54   \n",
       "1         0   19746.724395        26146.724395            41   \n",
       "2         0   11652.969918        22052.969918            57   \n",
       "3         0   11260.930936       115960.930936            39   \n",
       "4         0   27987.704652        31387.704652            39   \n",
       "...     ...            ...                 ...           ...   \n",
       "3995      0   18052.611626        67152.611626            42   \n",
       "3996      0   34949.202468        51749.202468            23   \n",
       "3997      0    4063.701410         9963.701410            44   \n",
       "3998      0   17390.520451        20490.520451            22   \n",
       "3999      0    2501.811593         8401.811593            57   \n",
       "\n",
       "      months_as_customer  num_claims_past_year  num_insurers_past_5_years  \\\n",
       "0                     94                     0                          1   \n",
       "1                    165                     0                          1   \n",
       "2                    155                     0                          1   \n",
       "3                     80                     0                          1   \n",
       "4                     60                     0                          1   \n",
       "...                  ...                   ...                        ...   \n",
       "3995                 103                     1                          1   \n",
       "3996                   6                     0                          3   \n",
       "3997                  35                     0                          2   \n",
       "3998                  38                     0                          1   \n",
       "3999                  74                     0                          1   \n",
       "\n",
       "      policy_deductable  policy_annual_premium  customer_zip  ...  \\\n",
       "0                   750                   3000         99207  ...   \n",
       "1                   750                   2950         95632  ...   \n",
       "2                   750                   3000         93203  ...   \n",
       "3                   750                   3000         85208  ...   \n",
       "4                   750                   3000         91792  ...   \n",
       "...                 ...                    ...           ...  ...   \n",
       "3995                750                   3000         93654  ...   \n",
       "3996                750                   3000         94305  ...   \n",
       "3997                750                   2550         95476  ...   \n",
       "3998                750                   3000         90680  ...   \n",
       "3999                900                   2650         98029  ...   \n",
       "\n",
       "      collision_type_missing  incident_severity_Major  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        1   \n",
       "...                      ...                      ...   \n",
       "3995                       0                        0   \n",
       "3996                       0                        0   \n",
       "3997                       0                        0   \n",
       "3998                       0                        1   \n",
       "3999                       0                        1   \n",
       "\n",
       "      incident_severity_Minor  incident_severity_Totaled  \\\n",
       "0                           1                          0   \n",
       "1                           0                          1   \n",
       "2                           1                          0   \n",
       "3                           1                          0   \n",
       "4                           0                          0   \n",
       "...                       ...                        ...   \n",
       "3995                        1                          0   \n",
       "3996                        0                          1   \n",
       "3997                        1                          0   \n",
       "3998                        0                          0   \n",
       "3999                        0                          0   \n",
       "\n",
       "      authorities_contacted_Ambulance  authorities_contacted_Fire  \\\n",
       "0                                   0                           0   \n",
       "1                                   0                           0   \n",
       "2                                   0                           0   \n",
       "3                                   0                           0   \n",
       "4                                   0                           0   \n",
       "...                               ...                         ...   \n",
       "3995                                0                           0   \n",
       "3996                                1                           0   \n",
       "3997                                0                           0   \n",
       "3998                                0                           0   \n",
       "3999                                0                           0   \n",
       "\n",
       "      authorities_contacted_None  authorities_contacted_Police  \\\n",
       "0                              1                             0   \n",
       "1                              0                             1   \n",
       "2                              0                             1   \n",
       "3                              1                             0   \n",
       "4                              0                             1   \n",
       "...                          ...                           ...   \n",
       "3995                           1                             0   \n",
       "3996                           0                             0   \n",
       "3997                           0                             1   \n",
       "3998                           0                             1   \n",
       "3999                           0                             1   \n",
       "\n",
       "      police_report_available_No  police_report_available_Yes  \n",
       "0                              1                            0  \n",
       "1                              0                            1  \n",
       "2                              0                            1  \n",
       "3                              1                            0  \n",
       "4                              1                            0  \n",
       "...                          ...                          ...  \n",
       "3995                           1                            0  \n",
       "3996                           1                            0  \n",
       "3997                           0                            1  \n",
       "3998                           0                            1  \n",
       "3999                           0                            1  \n",
       "\n",
       "[4000 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preproc_dir_artifact_file = os.path.join(train_preproc_dir_artifact,'train.csv')\n",
    "train_prep_df = pd.read_csv(train_preproc_dir_artifact_file)\n",
    "train_prep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 훈련 변수 및 하이퍼파라미터 설정\n",
    "- XGBoost에 알고리즘에 입력될 하이퍼 파리미터의 값을 설정 합니다.\n",
    "- scale_pos_weight 의 경우는 현재의 데이터가 레이블(fraud)간 불균형이 있기에, fraud: 1, non-fraud: 0 의 비율을 계산하여 제공합니다.\n",
    "    - 상세 사항은 여기를 보세요. -->  [XGBoost Parameters](https://xgboost.readthedocs.io/en/latest/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud_sum: 131 , non_fraud_sum: 3869, class_weight: 29\n"
     ]
    }
   ],
   "source": [
    "def get_pos_scale_weight(df, label):\n",
    "    '''\n",
    "    1, 0 의 레이블 분포를 계산하여 클래스 가중치 리턴\n",
    "    예: 1: 10, 0: 90 이면 90/10 = 9 를 제공함. \n",
    "    호출:\n",
    "        class_weight = get_pos_scale_weight(train_prep_df, label='fraud')\n",
    "    '''\n",
    "    fraud_sum = df[df[label] == 1].shape[0]\n",
    "    non_fraud_sum = df[df[label] == 0].shape[0]\n",
    "    class_weight = int(non_fraud_sum / fraud_sum)\n",
    "    print(f\"fraud_sum: {fraud_sum} , non_fraud_sum: {non_fraud_sum}, class_weight: {class_weight}\")\n",
    "    return class_weight\n",
    "    \n",
    "class_weight = get_pos_scale_weight(train_prep_df, label='fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'hyperparameters' (dict)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = project_prefix\n",
    "\n",
    "estimator_output_path = f's3://{bucket}/{prefix}/training_jobs'\n",
    "train_instance_count = 1\n",
    "\n",
    "hyperparameters = {\n",
    "       \"scale_pos_weight\" : class_weight,    \n",
    "        \"max_depth\": \"3\",\n",
    "        \"eta\": \"0.2\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"num_round\": \"100\",\n",
    "}\n",
    "%store hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 훈련 스크립트 확인\n",
    "\n",
    "전처리 코드는 크게 아래와 같이 구성 되어 있습니다.\n",
    "- 커맨드 인자로 전달된 변수 내용 확인\n",
    "- 훈련 데이터를 로딩 및 하이퍼파라미터 설정\n",
    "- xgboost의 cross-validation(cv) 로 훈련 합니다.\n",
    "- Cross-Validation으로 훈련하여, 훈련 및 검증 메트릭 추출\n",
    "- 훈련 및 검증 데이터 세트의 roc-auc 값을 metrics_data 에 저장\n",
    "- 오직 훈련 데이터 만으로 훈련하여 모델 생성\n",
    "- 모델 아티펙트 및 훈련/검증 지표를 저장\n",
    "    - [알림] 일반적으로 xgboost의 알고리즘의 큰 변경이 없으면, 세이지 메이커 내장 xgboost 알고리즘을 사용합니다. 여기서는 훈련 코드를 사용자가 정의해서 사용할 수 있는 예시를 위하여 따로 훈련 코드를 만들었습니다.\n",
    "    - [세이지메이커 XGBoost 알고리즘](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/xgboost.html)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mxgboost\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mxgb\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "pd.options.display.max_rows=\u001b[34m20\u001b[39;49;00m\n",
      "pd.options.display.max_columns=\u001b[34m10\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m###################################\u001b[39;49;00m\n",
      "    \u001b[37m## 커맨드 인자 처리\u001b[39;49;00m\n",
      "    \u001b[37m###################################    \u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# Hyperparameters are described here\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--scale_pos_weight\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m50\u001b[39;49;00m)    \n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--num_round\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m999\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--max_depth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m3\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--eta\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.2\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--objective\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mbinary:logistic\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--nfold\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m5\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--early_stopping_rounds\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train_data_path\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[37m# SageMaker specific arguments. Defaults are set in the environment variables.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    args = parser.parse_args()\n",
      "    \n",
      "    \u001b[37m###################################\u001b[39;49;00m\n",
      "    \u001b[37m## 데이터 세트 로딩 및 변환\u001b[39;49;00m\n",
      "    \u001b[37m###################################        \u001b[39;49;00m\n",
      "\n",
      "    data = pd.read_csv(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.train_data_path\u001b[33m}\u001b[39;49;00m\u001b[33m/train.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    train = data.drop(\u001b[33m'\u001b[39;49;00m\u001b[33mfraud\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, axis=\u001b[34m1\u001b[39;49;00m)\n",
      "    label = pd.DataFrame(data[\u001b[33m'\u001b[39;49;00m\u001b[33mfraud\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    dtrain = xgb.DMatrix(train, label=label)\n",
      "    \n",
      "    \u001b[37m###################################\u001b[39;49;00m\n",
      "    \u001b[37m## 하이퍼파라미터 설정\u001b[39;49;00m\n",
      "    \u001b[37m###################################        \u001b[39;49;00m\n",
      "    \n",
      "    params = {\u001b[33m'\u001b[39;49;00m\u001b[33mmax_depth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.max_depth, \u001b[33m'\u001b[39;49;00m\u001b[33meta\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.eta, \u001b[33m'\u001b[39;49;00m\u001b[33mobjective\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.objective, \u001b[33m'\u001b[39;49;00m\u001b[33mscale_pos_weight\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.scale_pos_weight}\n",
      "    \n",
      "    num_boost_round = args.num_round\n",
      "    nfold = args.nfold\n",
      "    early_stopping_rounds = args.early_stopping_rounds\n",
      "\n",
      "    \u001b[37m###################################\u001b[39;49;00m\n",
      "    \u001b[37m## Cross-Validation으로 훈련하여, 훈련 및 검증 메트릭 추출\u001b[39;49;00m\n",
      "    \u001b[37m###################################            \u001b[39;49;00m\n",
      "    \n",
      "    cv_results = xgb.cv(\n",
      "        params = params,\n",
      "        dtrain = dtrain,\n",
      "        num_boost_round = num_boost_round,\n",
      "        nfold = nfold,\n",
      "        early_stopping_rounds = early_stopping_rounds,\n",
      "        metrics = (\u001b[33m'\u001b[39;49;00m\u001b[33mauc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\n",
      "        stratified = \u001b[34mTrue\u001b[39;49;00m, \u001b[37m# 레이블 (0,1) 의 분포에 따라 훈련 , 검증 세트 분리\u001b[39;49;00m\n",
      "        seed = \u001b[34m0\u001b[39;49;00m\n",
      "        )\n",
      "    \n",
      "    \u001b[37m###################################\u001b[39;49;00m\n",
      "    \u001b[37m## 훈련 및 검증 데이터 세트의 roc-auc 값을 metrics_data 에 저장\u001b[39;49;00m\n",
      "    \u001b[37m###################################            \u001b[39;49;00m\n",
      "\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mcv_results: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, cv_results)\n",
      "\n",
      "    \u001b[37m# Select the best score\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m[0]#011train-auc:\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcv_results.iloc[-\u001b[34m1\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mtrain-auc-mean\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m[1]#011validation-auc:\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcv_results.iloc[-\u001b[34m1\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mtest-auc-mean\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    metrics_data = {\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mclassification_metrics\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation:auc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: { \u001b[33m'\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: cv_results.iloc[-\u001b[34m1\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mtest-auc-mean\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]},\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtrain:auc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: {\u001b[33m'\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: cv_results.iloc[-\u001b[34m1\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mtrain-auc-mean\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]}\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    \u001b[37m###################################\u001b[39;49;00m\n",
      "    \u001b[37m## 오직 훈련 데이터 만으로 훈련하여 모델 생성\u001b[39;49;00m\n",
      "    \u001b[37m###################################            \u001b[39;49;00m\n",
      "\n",
      "    model = xgb.train(params=params, dtrain=dtrain, num_boost_round=\u001b[36mlen\u001b[39;49;00m(cv_results))\n",
      "\n",
      "    \u001b[37m###################################\u001b[39;49;00m\n",
      "    \u001b[37m## 모델 아티펙트 및 훈련/검증 지표를 저장\u001b[39;49;00m\n",
      "    \u001b[37m###################################            \u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# Save the model to the location specified by ``model_dir``\u001b[39;49;00m\n",
      "    metrics_location = args.output_data_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/metrics.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    model_location = args.model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/xgboost-model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    \n",
      "    \n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(metrics_location, \u001b[33m'\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        json.dump(metrics_data, f)\n",
      "    \n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_location, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        pickle.dump(model, f)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/xgboost_starter_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 훈련 스텝 개발 및 실행\n",
    "\n",
    "## 3.1 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) **[로컬 노트북 인스턴스]**에서 다커 컨테이너로 훈련 코드 실행 (로컬 모드로 불리움)\n",
    "- 이 단계의 목적은 현업 프로젝트의 개발시에 로컬 노트북 인스턴스의 다커 컨테이터 안에서 로직 확인, 디버깅이 수월하기 때문에 단계를 진행 합니다. \n",
    "    - 처음 실행시에 다커 이미지를 로컬 노트북 인스턴스에 다운로드 받는데에 1-2분 소요 됩니다. \n",
    "    - 로컬 노트북 인스턴스의 다커 컨테이너로 실행하기 이전에, 쥬피터 노트북에서 훈련 코드를 실행할 수 있습니다. 이 노트북에서는 이 과정을 생략 했습니다.\n",
    "- [알림] 로컬 모드 참고 자료\n",
    "    - 로컬모드 설명하는 블로그 자료 --> [Use the Amazon SageMaker local mode to train on your notebook instance](https://aws.amazon.com/blogs/machine-learning/use-the-amazon-sagemaker-local-mode-to-train-on-your-notebook-instance/)\n",
    "    - TF, Pytorch, SKLean, SKLearn Processing JOb에 대한 로컬 모드 샘플 --> [Amazon SageMaker Local Mode Examples](https://github.com/aws-samples/amazon-sagemaker-local-mode)\n",
    "    - Python SDK -->  [로컬모드 Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html#local-mode)\n",
    "    - [SageMaker 에서 도커 컨테이너 사용하기](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/docker-containers.html)\n",
    "    - [Hello 다커](https://github.com/mullue/hello-docker/blob/master/hello_docker.ipynb)\n",
    "\n",
    "    \n",
    "### (2) **[세이지 메이커 호스트 모드]** 로 (**로컬 노트북 인스턴스에서 실행이 되는 것이 아님**) 다커 컨테이너를 통해서 훈련 코드 실행      \n",
    "- 위의 (1) 단계에서 훈련 코드의 로직 확인이 되었기에, 실제 세이지 메이커의 호스트 모드로 다커 컨테이너를 통해 훈련 코드를 수행 합니다.\n",
    "- 이 단계의 목적은 SageMaker Model Building Pipeline이 다커 컨테이너 형태로 실행이 되기에, 이 단계에서 다커 컨테이너에서 정상적으로 동작하는지를 확인하기 위해서 이 단계를 수행 합니다.\n",
    "\n",
    "    \n",
    "### (3) SageMaker Model Building Pipeline 에서 훈련을 수행합니다.\n",
    "- 상세 사항은 여기에서 확인 하세요. --> [Amazon SageMaker 모델 구축 파이프라인](img/https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines.html)\n",
    "    \n",
    "---    \n",
    "    \n",
    "## 3.2 실행\n",
    "### (1) **[로컬 노트북 인스턴스]**에서 다커 컨테이너로 훈련 코드 실행 (로컬 모드로 불리움)\n",
    "- 최초 실행시에 약 1-3분 소요 됩니다.\n",
    "- `instance_type=local` 를 제공해서 로컬 모드로 동작합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point = \"xgboost_starter_script.py\",\n",
    "    source_dir = \"src\",\n",
    "    output_path = estimator_output_path,\n",
    "    code_location = estimator_output_path,\n",
    "    hyperparameters = hyperparameters,\n",
    "    role = role,\n",
    "    instance_count = train_instance_count,\n",
    "    instance_type = 'local',\n",
    "    framework_version = \"1.0-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 9ufwnw4lic-algo-1-5pfl2 ... \n",
      "Creating 9ufwnw4lic-algo-1-5pfl2 ... done\n",
      "Attaching to 9ufwnw4lic-algo-1-5pfl2\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m INFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m INFO:sagemaker_xgboost_container.training:Invoking user training script.\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m INFO:sagemaker-containers:Module xgboost_starter_script does not provide a setup.py. \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m Generating setup.py\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m INFO:sagemaker-containers:Generating setup.cfg\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m INFO:sagemaker-containers:Generating MANIFEST.in\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m INFO:sagemaker-containers:Installing module with the following command:\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m Building wheels for collected packages: xgboost-starter-script\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m   Building wheel for xgboost-starter-script (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m \u001b[?25h  Created wheel for xgboost-starter-script: filename=xgboost_starter_script-1.0.0-py2.py3-none-any.whl size=29311 sha256=a06e278a8a957730e2275b5cf3acee2d8c8fc5070a01c6ce6a7c7b26a8b72e76\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-oaaz9hhm/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m Successfully built xgboost-starter-script\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m Installing collected packages: xgboost-starter-script\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m Successfully installed xgboost-starter-script-1.0.0\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m INFO:sagemaker-containers:Invoking user script\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m Training Env:\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m {\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     },\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"current_host\": \"algo-1-5pfl2\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"algo-1-5pfl2\"\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     ],\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"scale_pos_weight\": 29,\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"max_depth\": \"3\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"eta\": \"0.2\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"objective\": \"binary:logistic\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"num_round\": \"100\"\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     },\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"train\": {\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         }\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     },\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"job_name\": \"sagemaker-xgboost-2021-07-11-02-40-54-820\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"master_hostname\": \"algo-1-5pfl2\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-057716757052/sagemaker-pipeline-step-by-step/training_jobs/sagemaker-xgboost-2021-07-11-02-40-54-820/source/sourcedir.tar.gz\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"module_name\": \"xgboost_starter_script\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"current_host\": \"algo-1-5pfl2\",\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m             \"algo-1-5pfl2\"\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m         ]\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     },\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m     \"user_entry_point\": \"xgboost_starter_script.py\"\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m }\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m Environment variables:\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_HOSTS=[\"algo-1-5pfl2\"]\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_HPS={\"eta\":\"0.2\",\"max_depth\":\"3\",\"num_round\":\"100\",\"objective\":\"binary:logistic\",\"scale_pos_weight\":29}\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_USER_ENTRY_POINT=xgboost_starter_script.py\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-5pfl2\",\"hosts\":[\"algo-1-5pfl2\"]}\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_CURRENT_HOST=algo-1-5pfl2\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_MODULE_NAME=xgboost_starter_script\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-057716757052/sagemaker-pipeline-step-by-step/training_jobs/sagemaker-xgboost-2021-07-11-02-40-54-820/source/sourcedir.tar.gz\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-5pfl2\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-5pfl2\"],\"hyperparameters\":{\"eta\":\"0.2\",\"max_depth\":\"3\",\"num_round\":\"100\",\"objective\":\"binary:logistic\",\"scale_pos_weight\":29},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2021-07-11-02-40-54-820\",\"log_level\":20,\"master_hostname\":\"algo-1-5pfl2\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-057716757052/sagemaker-pipeline-step-by-step/training_jobs/sagemaker-xgboost-2021-07-11-02-40-54-820/source/sourcedir.tar.gz\",\"module_name\":\"xgboost_starter_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-5pfl2\",\"hosts\":[\"algo-1-5pfl2\"]},\"user_entry_point\":\"xgboost_starter_script.py\"}\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_USER_ARGS=[\"--eta\",\"0.2\",\"--max_depth\",\"3\",\"--num_round\",\"100\",\"--objective\",\"binary:logistic\",\"--scale_pos_weight\",\"29\"]\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_HP_SCALE_POS_WEIGHT=29\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_HP_MAX_DEPTH=3\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_HP_ETA=0.2\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_HP_OBJECTIVE=binary:logistic\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m SM_HP_NUM_ROUND=100\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m /miniconda3/bin/python3 -m xgboost_starter_script --eta 0.2 --max_depth 3 --num_round 100 --objective binary:logistic --scale_pos_weight 29\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m \n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m cv_results:      train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 0         0.819224       0.005816       0.769926      0.047341\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 1         0.842821       0.012217       0.806518      0.021315\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 2         0.854213       0.005705       0.806512      0.021542\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 3         0.861384       0.008274       0.812600      0.030358\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 4         0.873625       0.009501       0.814151      0.032305\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 5         0.881067       0.009787       0.813072      0.027425\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 6         0.886745       0.009047       0.810738      0.025871\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 7         0.895144       0.009728       0.816828      0.023247\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 8         0.898417       0.008864       0.817527      0.025424\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 9         0.903438       0.010093       0.818247      0.024297\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 10        0.909567       0.013376       0.818719      0.021123\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 11        0.913054       0.013701       0.817377      0.019645\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 12        0.918236       0.012743       0.820624      0.020702\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 13        0.921825       0.012667       0.820398      0.020053\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 14        0.926449       0.009542       0.818657      0.017779\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 15        0.930879       0.009050       0.821708      0.018292\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 16        0.935445       0.010258       0.821715      0.020194\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m 17        0.940519       0.006538       0.821841      0.020128\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m [0]#011train-auc:0.9405190000000001\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 |\u001b[0m [1]#011validation-auc:0.8218406\n",
      "\u001b[36m9ufwnw4lic-algo-1-5pfl2 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmp5940ay60/algo-1-5pfl2 Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator.fit(inputs = {'train': train_preproc_dir_artifact})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 세이지메이커 호스트 모드(로컬 다커 컨테이너 사용)로 훈련 코드 실행\n",
    "- `instance_type = 'ml.m5.xlarge'` 를 제공해서 ml.m5.xlarge EC2 인스턴스를 생성하고, 아 안에서 모델 훈련이 진행 됩니다.\n",
    "- `xgb_estimator.fit(inputs = {'train': train_preproc_dir_artifact}, wait=False)` 에서 wait=False 를 제공했기 때문에 노트북에서는 비동기로 진행합니다. 즉 셀이 완료까지 기다리지 않고 다음 셀의 실행이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.m5.xlarge'\n",
    "\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point = \"xgboost_starter_script.py\",\n",
    "    source_dir = \"src\",\n",
    "    output_path = estimator_output_path,\n",
    "    code_location = estimator_output_path,\n",
    "    hyperparameters = hyperparameters,\n",
    "    role = role,\n",
    "    instance_count = train_instance_count,\n",
    "    instance_type = instance_type,\n",
    "    framework_version = \"1.0-1\")\n",
    "\n",
    "xgb_estimator.fit(inputs = {'train': train_preproc_dir_artifact}, wait=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련 잡을 SageMaker Console에서 확인\n",
    "- 실제 SageMaker Console에 이동하셔서 훈련 잡이 실행 중인지 확인 해보세요.\n",
    "![train_job_console.png](img/train_job_console.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) SageMaker Pipeline에서  실행 \n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 빌딩 파이프라인 변수 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "training_instance_count = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value= 1\n",
    ")\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습을 위한 학습단계 정의 \n",
    "\n",
    "본 단계에서는 SageMaker의 [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) 알고리즘을 이용하여 학습을 진행할 것입니다. XGBoost 알고리즘을 이용하도록 Estimator를 구성합니다. 보편적인 학습스크립트를 이용하여 입력 채널에서 정의한 학습데이터를 로드하고, 하이퍼파라미터 설정을 통해 학습을 설정하고, 모델을 학습한 후 `model_dir`경로에 학습된 모델을 저장합니다. 저장된 모델은 이후 호스팅을 위해 사용됩니다. \n",
    "\n",
    "학습된 모델이 추출되어 저장될 경로 또한 명시되었습니다. \n",
    "\n",
    "`training_instance_type`파라미터가 사용된 것을 확인합니다. 이 값은 본 예제의 파이프라인에서 여러번 사용됩니다. 본 단계에서는 estimator를 선언할 때 전달되었습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = XGBoost(\n",
    "    entry_point = \"xgboost_starter_script.py\",\n",
    "    source_dir = \"src\",\n",
    "    output_path = estimator_output_path,\n",
    "    code_location = estimator_output_path,\n",
    "    hyperparameters = hyperparameters,\n",
    "    role = role,\n",
    "    instance_count = training_instance_count,\n",
    "    instance_type = training_instance_type,\n",
    "    framework_version = \"1.0-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 단계에서 (프로세싱) 전처리 훈련, 검증 데이터 세트를 입력으로 제공 합니다.\n",
    "- [알림] `8.5.All-Pipeline.ipynb` 노트북에서는 입력을 전처리 스텝의 결과를 지정합니다. 여기서는 전처리 스텝과 독립적으로 실행하기 위해서 S3의 입력 파일 경로를 직접 기술 하였습니다.\n",
    "-  `8.5.All-Pipeline.ipynb` 에서의 step_train 코드\n",
    "\n",
    "```python\n",
    "step_train = TrainingStep(\n",
    "    name=\"FraudScratchTrain\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "    },\n",
    ")    \n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"FraudScratchTrain\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data= train_preproc_dir_artifact,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 빌딩 파이프라인 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = project_prefix\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        training_instance_type,        \n",
    "        training_instance_count,         \n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_train],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "# definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인을 SageMaker에 제출하고 실행하기 \n",
    "\n",
    "파이프라인 정의를 파이프라인 서비스에 제출합니다. 함께 전달되는 역할(role)을 이용하여 AWS에서 파이프라인을 생성하고 작업의 각 단계를 실행할 것입니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:ap-northeast-2:057716757052:pipeline/sagemaker-pipeline-step-by-step',\n",
       " 'ResponseMetadata': {'RequestId': '6b1b5f55-766f-48aa-9ccf-7cc500d85fe9',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '6b1b5f55-766f-48aa-9ccf-7cc500d85fe9',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '104',\n",
       "   'date': 'Sun, 11 Jul 2021 02:42:06 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디폴트값을 이용하여 파이프라인을 샐행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 운영: 파이프라인 대기 및 실행상태 확인\n",
    "\n",
    "워크플로우의 실행상황을 살펴봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:ap-northeast-2:057716757052:pipeline/sagemaker-pipeline-step-by-step',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:ap-northeast-2:057716757052:pipeline/sagemaker-pipeline-step-by-step/execution/w50nnwbwq50a',\n",
       " 'PipelineExecutionDisplayName': 'execution-1625971327632',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2021, 7, 11, 2, 42, 7, 570000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2021, 7, 11, 2, 42, 7, 570000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {},\n",
       " 'LastModifiedBy': {},\n",
       " 'ResponseMetadata': {'RequestId': '1d5feeae-e952-49c7-b981-95a24e13633f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1d5feeae-e952-49c7-b981-95a24e13633f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '435',\n",
       "   'date': 'Sun, 11 Jul 2021 02:42:07 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행이 완료될 때까지 기다립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행된 단계들을 리스트업합니다. 파이프라인의 단계실행 서비스에 의해 시작되거나 완료된 단계를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'FraudScratchTrain',\n",
       "  'StartTime': datetime.datetime(2021, 7, 11, 2, 42, 8, 149000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2021, 7, 11, 2, 45, 20, 682000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:ap-northeast-2:057716757052:training-job/pipelines-w50nnwbwq50a-fraudscratchtrain-kcbrltgfm6'}}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Studio에서 확인하기\n",
    "- 이전의 3.1.Preprocesing-Pipleline 노트북에서 언급 되었듯이, SageMaker Studio 에서도 확인이 가능합니다. 이전 노트북을 참조 해주세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아티펙트 경로 추출\n",
    "위의 훈련 스텝이 완료되면 실행해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train_model_artifact:  s3://sagemaker-ap-northeast-2-057716757052/sagemaker-pipeline-step-by-step/training_jobs/pipelines-w50nnwbwq50a-FraudScratchTrain-KCbrlTgFm6/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "def get_train_artifact(execution, client, job_type,  kind=0):\n",
    "    '''\n",
    "    kind: 0 --> train\n",
    "    kind: 2 --> test\n",
    "    '''\n",
    "    response = execution.list_steps()\n",
    "    # print(\"response: \", response)\n",
    "    proc_arn = response[0]['Metadata'][job_type]['Arn']\n",
    "    train_job_name = proc_arn.split('/')[-1]\n",
    "    # print(\"train_job_name: \", train_job_name)\n",
    "    response = client.describe_training_job(TrainingJobName = train_job_name)\n",
    "    # print(\"\\nresponse: \", response)    \n",
    "    train_model_artifact = response['ModelArtifacts']['S3ModelArtifacts']    \n",
    "    \n",
    "    return train_model_artifact\n",
    "\n",
    "import boto3\n",
    "client = boto3.client(\"sagemaker\")\n",
    "    \n",
    "train_model_artifact = get_train_artifact(execution, client,job_type='TrainingJob', kind=0)\n",
    "print(\" train_model_artifact: \", train_model_artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = xgb_train.image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 모델 아티펙트와, 훈련시 사용한 다커 이미지의 경로를 저장 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_model_artifact' (str)\n",
      "Stored 'image_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store train_model_artifact\n",
    "%store image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
